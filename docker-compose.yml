# Setup for Linux WSL runtime on windows
services:
  ollama:
    image: ollama/ollama:0.12.10
    container_name: ollama
    networks:
      - local_net
    # IMPORTANT: The host port is 11435, the container port is 11434
    ports:
      - "11434:11434"
    volumes:
      # ðŸ”‘ CRITICAL WSL CHANGE: C:/... must become /c/... for WSL volume binding
      - ./data/ollama:/root/.ollama
    # ðŸŒŸ WSL 2/Linux GPU Configuration (Recommended for Docker Compose) ðŸŒŸ
    deploy:
      resources:
        reservations:
          devices:
            # This ensures your RTX 5080 is correctly exposed to the container via WSL
            - driver: nvidia
              count: all
              capabilities: [gpu]
      restart_policy:
        condition: unless-stopped
    environment:
      # Kept your original environment variables
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_PORT=11434
      - OLLAMA_KEEP_ALIVE=1h
    healthcheck:
      test: ["CMD", "ollama", "--version"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    platform: linux/amd64
    # This host-gateway extra host remains, though usually not needed for inter-container chat
    extra_hosts:
      - "ollama:host-gateway"
      
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: openwebui
    networks:
      - local_net
    # Host port 8081 maps to container port 8080
    ports:
      - "8081:8080"
    volumes:
      # ðŸ”‘ CRITICAL WSL CHANGE: C:/... must become /c/... for WSL volume binding
      - ./data/openwebui:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_NAME=OpenWebUI
      - WEBUI_VERSION=latest
      - RAG_ENABLED=true  # Enable RAG
      - RAG_MODEL=sentence-transformers/all-mpnet-base-v2 # Popular embedding model
      - RAG_INDEX=faiss  # Use FAISS for indexing
      - RAG_TOP_K=7 # Retrieve top 5 documents
      - SEARCH_URL=http://searxng:8080/search?q=<query>
    depends_on:
      ollama:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: unless-stopped
    platform: linux/amd64
    extra_hosts:
      - "ollama:host-gateway"

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    restart: unless-stopped
    networks:
      - local_net
    ports:
      - "8082:8080"
    volumes:
      - ./config/searxng-config:/etc/searxng
      - ./data/searxng-data:/var/lib/searxng
    environment:
      - SEARXNG_BASE_URL=http://searxng:8082
    depends_on:
      - ollama

networks:
  local_net:
    driver: bridge