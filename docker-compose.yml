services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    networks:
      - local_net
    ports:
      - "11435:11434"
    deploy:
      restart_policy:
        condition: unless-stopped
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_PORT=11434
    healthcheck:
      test: ollama --version || exit 1
    platform: linux/amd64
    extra_hosts:
      - "ollama:host-gateway"
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: openwebui
    networks:
      - local_net
    ports:
      - "8081:8080"
    volumes:
      - C:/open_webui:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_NAME=OpenWebUI
      - WEBUI_VERSION=main
#      - SEARCH_URL=http://searxng:8080/search  # Changed from 8082 to 8080
    depends_on:
      ollama:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: unless-stopped
    platform: linux/amd64
    extra_hosts:
      - "ollama:host-gateway"
  # searxng:
  #   image: searxng/searxng:latest
  #   container_name: searxng
  #   networks:
  #     - local_net
  #   ports:
  #     - "8082:8080"  # This is correct - host port 8082 maps to container port 8080
  #   volumes:
  #     - C:/searxng_config:/etc/searxng
  #   environment:
  #     - SEARXNG_BASE_URL=http://localhost:8082
  #   deploy:
  #     restart_policy:
  #       condition: unless-stopped
  #   platform: linux/amd64
networks:
  local_net:
    driver: bridge